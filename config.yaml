model:
  name: "distilbert-base-uncased"
  # name: "bert-base-uncased"
  # name: "bert-large-uncased"
  # name: "roberta-base"
#  name: "roberta-large"
  # name: "microsoft/deberta-v3-large"
  # name: "huawei-noah/TinyBERT_General_4L_312D"
  # name: "bert-large-uncased"
  num_labels: 3
  model_cfg:
    hidden_sizes: []

  # model_state_dict: "bert-large-uncased_20240327_123313.pth"
  # model_state_dict: "roberta-large_20240327_103801.pth"

  # model_state_dict: "distilbert-base-uncased_20240323_164414.pth"


  # model_state_dict: "roberta-large_20240327_103801.pth"
  # model_state_dict: "roberta-large_20240327_103720.pth"
  # model_state_dict: "bert-large-uncased_20240327_123313.pth"
  # model_state_dict: "roberta-large_20240327_174024.pth"
  model_state_dict: "deberta-v3-large_20240329_115256.pth"
  # model_state_dict: "deberta-v3-large_20240329_024714.pth"
  # model_state_dict: "bert-base-uncased_20240328_201206.pth"
  # model_state_dict: "roberta-base_20240328_200823.pth"
  # model_state_dict: "TinyBERT_General_4L_312D_20240328_145724.pth"
  # model_state_dict: "bert-large-uncased_20240327_173829.pth"
  # model_state_dict: "bert-large-uncased_20240327_103627.pth"
  # model_state_dict: "bert-large-uncased_20240327_173829.pth"

data:
  name: "snli"
  filter_label: -1
  max_length: 128
  batch_size: 12
  subset_ratio: 0.1
  # batch_size: 10
  augmentation: false

optimizer:
  name: "Adam"
  lr: 5e-6

training:
  num_epochs: 40
  use_gpu: true

  unfreeze_epoch: 0

  use_wandb: true
  wandb_project: "NLP_LAB_CS"
  wandb_entity: "dips_learning_2023"

  use_reduce_lr: true
  reduce_lr_factor: 0.5
  reduce_lr_patience: 0

  use_warmup: false
  warmup_proportion: 0.05
